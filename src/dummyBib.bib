@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{vaswani2023attention,
      title={Attention Is All You Need},
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{CHOW2008961,
title = {A survey study of critical success factors in agile software projects},
journal = {Journal of Systems and Software},
volume = {81},
number = {6},
pages = {961-971},
year = {2008},
note = {Agile Product Line Engineering},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2007.08.020},
url = {https://www.sciencedirect.com/science/article/pii/S0164121207002208},
author = {Tsun Chow and Dac-Buu Cao},
}

@book{cohn2005agile,
  title={Agile Estimating and Planning},
  author={Cohn, Mike},
  year={2005},
  publisher={Pearson}
}

@INPROCEEDINGS{1667560,
  author={Haugen, N.C.},
  booktitle={AGILE 2006 (AGILE'06)},
  title={An empirical study of using planning poker for user story estimation},
  year={2006},
  volume={},
  number={},
  pages={9 pp.-34},
  keywords={Process planning;Contracts;Software performance;Delay estimation;Estimation error;Computer industry;Resource management;Programming;Software testing;Strategic planning},
  doi={10.1109/AGILE.2006.16}}

@ARTICLE{10243029,
  author={Rashid, Chaudhary Hamza and Shafi, Imran and Ahmad, Jamil and Thompson, Ernesto Bautista and Vergara, Manuel Masias and de la Torre Diez, Isabel and Ashraf, Imran},
  journal={IEEE Access},
  title={Software Cost and Effort Estimation: Current Approaches and Future Trends},
  year={2023},
  volume={11},
  number={},
  pages={99268-99288},
  keywords={Estimation;Costs;Maximum likelihood estimation;Software algorithms;Systematics;Organizations;Software quality;Quality assessment;Project management;Software cost estimation;systematic literature review;tollgate approach;Likert scale;quality assessment;software dependability;project planning},
  doi={10.1109/ACCESS.2023.3312716}}

@inproceedings{chatgpt_paraphraser,
  author={Vladimir Vorobev, Maxim Kuznetsov},
  title={A paraphrasing model based on ChatGPT paraphrases},
  year={2023}
}

@misc{bert-base-uncased,
	title = {google-bert/bert-base-uncased - {H}ugging {F}ace huggingface.co},
	howpublished = {\url{https://huggingface.co/google-bert/bert-base-uncased}},
	note = {[Accessed 17-03-2024]}
}

@inproceedings{tabassum2020code,
    title={Code and Named Entity Recognition in StackOverflow},
    author={Tabassum, Jeniya  and Maddela, Mounica  and Xu, Wei and Ritter, Alan },
    booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)},
    url={https://www.aclweb.org/anthology/2020.acl-main.443/},
    year = {2020},
}
@misc{sanh2020distilbert,
      title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
      author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
      year={2020},
      eprint={1910.01108},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{ma2019nlpaug,
  title={NLP Augmentation},
  author={Edward Ma},
  howpublished={https://github.com/makcedward/nlpaug},
  year={2019}
}

@misc{mosbach2021stability,
      title={On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines},
      author={Marius Mosbach and Maksym Andriushchenko and Dietrich Klakow},
      year={2021},
      eprint={2006.04884},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{adamPytorch,
    url={https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html#adamw},
    title={torch.optim.AdamW},
    author={PyTorch}}


@misc{transformerLinearSchedular,
  url={https://huggingface.co/docs/transformers/en/main_classes/optimizer_schedules#transformers.get_linear_schedule_with_warmup},
    title={transformers.get\_linear\_schedule\_with\_warmup},
    author={Hugging Face}}









